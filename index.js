import * as core from '@actions/core';
import * as github from '@actions/github';
import OpenAI from 'openai';

/**
 * Main function that executes the GitHub action
 * Connects to Deepseek, analyzes logs and comments on the PR
 */
async function main() {
  try {
    // 1. Read inputs defined in action.yml
    const githubToken = core.getInput('github_token');
    const deepseekApiKey = core.getInput('deepseek_api_key');
    const logContent = core.getInput('log_content');

    // Validate inputs
    if (!githubToken) {
      throw new Error('GitHub token is required to comment on the PR');
    }

    if (!deepseekApiKey) {
      throw new Error('Deepseek API key is required to connect to the service');
    }

    // 2. Initialize "OpenAI" client pointing to Deepseek
    const openai = new OpenAI({
      baseURL: 'https://api.deepseek.com', // Deepseek endpoint
      apiKey: deepseekApiKey
    });

    // Determine if we have log content to analyze
    if (!logContent || logContent.trim() === '') {
      core.warning('No log content was provided to interpret. A generic message will be sent.');
    }

    // 3. Build an appropriate prompt to interpret logs
    const systemPrompt = `
You are an expert in interpreting computer system logs. Your task is to:

1. Analyze the provided log content
2. Identify patterns, errors, warnings, and important events
3. Explain in clear language what is happening
4. Suggest possible solutions if you detect problems
5. Organize your response with markdown formatting for easy reading

If the log contains errors, explain what they mean and how to resolve them. If there are no obvious errors, summarize the main events from the log.
`;

    // 4. Call the "deepseek-chat" model with log content
    const completion = await openai.chat.completions.create({
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: logContent || "No log content was provided for analysis." }
      ],
      model: "deepseek-chat",
      temperature: 0.5, // Reduce temperature for more precise responses
      max_tokens: 1000  // Allow longer responses for complete analysis
    });

    // 5. Get the response
    const responseText = completion.choices[0].message.content;
    console.log("Deepseek analysis completed");

    // 6. Format the response for the comment
    const formattedResponse = formatResponse(responseText);

    // 7. If a PR number exists in the context, comment on the PR
    await commentOnPR(githubToken, formattedResponse);
    
    // Set the response as the action's output
    core.setOutput("interpretation", responseText);
    
  } catch (error) {
    // If there's an error, mark the action as failed
    console.error("Error:", error.message);
    core.setFailed(error.message);
  }
}

/**
 * Formats the Deepseek response in a structured comment
 * @param {string} responseText - Response text from Deepseek
 * @returns {string} - Formatted comment
 */
function formatResponse(responseText) {
  return `
## ðŸ¤– Log Analysis by Voltaflow

${responseText}

---
*This analysis was automatically generated by voltaflow-pr-check.*
`;
}

/**
 * Comments on the PR with the log analysis
 * @param {string} token - GitHub token
 * @param {string} body - Comment content
 */
async function commentOnPR(token, body) {
  const prNumber = github.context.issue.number;
  
  if (prNumber) {
    const octokit = github.getOctokit(token);
    await octokit.rest.issues.createComment({
      owner: github.context.repo.owner,
      repo: github.context.repo.repo,
      issue_number: prNumber,
      body: body
    });
    console.log(`Comment added to PR #${prNumber}`);
  } else {
    console.log("No associated PR was found. Displaying results in the console:");
    console.log(body);
  }
}

// Execute the main function
main();
